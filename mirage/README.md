# Mirage

> **Live Demo:** [sr-mirage.vercel.app](https://sr-mirage.vercel.app)

A sketch-to-code AI that transforms hand-drawn wireframes into production-ready React components with live preview, powered by tldraw and WebContainers.

## ğŸŒ Overview

Mirage combines a full-featured drawing canvas with an in-browser Vite development environment. Draw your UI concepts, click "Make It Real," and watch as AI generates working React/Tailwind code rendered in a live preview â€” all running client-side.

## ğŸ¤– AI Integration

**Models:** Ollama-compatible LLMs (llama3, deepseek-coder, mistral, etc.)

**Runtime:** Local Ollama server with streaming responses

**Capabilities:**

- Scene-to-prompt conversion (shapes, positions, labels extracted)
- React/Tailwind code generation optimized for production
- Iterative refinement via natural language chat
- Context-aware modifications to existing code

**Technical Details:**

- Streaming responses for real-time generation feedback
- Temperature tuned to 0.2 for precise code output
- 4K context window for complex components
- Auto-model selection prioritizing coding-optimized models

## âœ¨ Features

### ğŸ¨ Canvas-to-Code Pipeline

- **tldraw Integration** â€” Full-featured vector canvas with shapes, arrows, text
- **Scene Analysis** â€” Extracts element hierarchy, positions, and labels
- **Instant Generation** â€” Click "Make It Real" to generate React/JSX

### âš¡ In-Browser Preview

- **WebContainer Runtime** â€” Complete Vite + React dev server running client-side
- **Hot Module Replacement** â€” Changes update instantly
- **Zero Backend** â€” Everything runs locally in your browser

### ğŸ’¬ Iterative Refinement

- **Chat Interface** â€” Describe modifications in natural language
- **Code-Aware Edits** â€” AI reads current code before applying changes
- **Rapid Iteration** â€” Tweak colors, layout, components conversationally

### ğŸŒ™ Design System

- **Cyberpunk Aesthetic** â€” Dark theme with violet/cyan ambient glows
- **Glassmorphism UI** â€” Frosted glass panels and subtle blur effects
- **Framer Motion** â€” Smooth animations and micro-interactions
- **Resizable Panels** â€” Adjust canvas, preview, and chat proportions

## ğŸš€ Getting Started

### Prerequisites

1. **Install Ollama** â€” [ollama.ai/download](https://ollama.ai/download)
2. **Pull a model:**
   ```bash
   ollama pull llama3
   # OR for better code generation:
   ollama pull deepseek-coder
   ```
3. **Start Ollama:**
   ```bash
   ollama serve
   ```

### Run Mirage

```bash
# Install dependencies
npm install

# Run development server
npm run dev

# Open browser
open http://localhost:3000
```

## ğŸ—ï¸ Architecture

```
mirage/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/ollama/     # Ollama proxy bridge
â”‚   â”‚   â””â”€â”€ page.tsx        # Main workspace
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ ui/             # ChatPanel, ModelManager, Logo
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ use-webcontainer.ts  # WebContainer singleton
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ ai/
â”‚       â”‚   â”œâ”€â”€ engine.ts   # Ollama client with streaming
â”‚       â”‚   â””â”€â”€ prompt.ts   # Scene-to-prompt converter
â”‚       â”œâ”€â”€ templates.ts    # Base Vite project files
â”‚       â””â”€â”€ webcontainer.ts # File operations
```

## âš ï¸ Requirements

- **Modern Browser** â€” Chrome/Edge with cross-origin isolation support
- **Ollama** â€” Running locally on port 11434
- **Memory** â€” 8GB+ RAM for model inference

## ğŸ”’ Security Notes

- **Cross-Origin Isolation** â€” Requires `Cross-Origin-Embedder-Policy: require-corp`
- **Local Only** â€” Ollama bridge connects to `127.0.0.1:11434`
- **Ephemeral Storage** â€” WebContainer filesystem resets on reload

---

_Built by [Sreekar Reddy](https://github.com/esreekarreddy)_
